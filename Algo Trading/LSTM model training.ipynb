{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key features in v8:\n",
    "\n",
    "1. Long Short\n",
    "\n",
    "Reference\n",
    "Binance Margin Bracket\n",
    "https://www.binance.com/en/futures/trading-rules/quarterly/leverage-margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 01:04:33.357776: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ta\n",
    "\n",
    "import keras\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSMA(data, sma_start: int, sma_end: int, sma_step: int):\n",
    "    sma_range = range(sma_start, sma_end, sma_step)\n",
    "\n",
    "    for window in sma_range:\n",
    "        # SMA/Close\n",
    "        # relative value of SMA to closing price\n",
    "        data.loc[:,f\"SMA_{window}\"] = ta.trend.SMAIndicator(data.Close, window=window).sma_indicator() / data.Close\n",
    "\n",
    "    for i in range(len(sma_range)):\n",
    "        for j in range(i+1, len(sma_range)):\n",
    "            # (SMA_1 - SMA_2) / Close\n",
    "            data.loc[:,f\"SMA_DELTA_{sma_range[i]}_{sma_range[j]}\"] = data.loc[:,f\"SMA_{sma_range[i]}\"] - data.loc[:,f\"SMA_{sma_range[j]}\"]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addEMA(data, ema_start: int, ema_end: int, ema_step: int):\n",
    "    ema_range = range(ema_start, ema_end, ema_step)\n",
    "\n",
    "    for window in ema_range:\n",
    "        # EMA/Close\n",
    "        # relative value of EMA to closing price\n",
    "        data.loc[:,f\"EMA_{window}\"] = ta.trend.EMAIndicator(data.Close, window=window).ema_indicator() / data.Close\n",
    "\n",
    "    for i in range(len(ema_range)):\n",
    "        for j in range(i+1, len(ema_range)):\n",
    "            # (EMA_1 - EMA_2) / Close\n",
    "            data.loc[:,f\"EMA_DELTA_{ema_range[i]}_{ema_range[j]}\"] = data.loc[:,f\"EMA_{ema_range[i]}\"] - data.loc[:,f\"EMA_{ema_range[j]}\"]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation(\n",
    "    data,\n",
    "    sma_start: int = 20,\n",
    "    sma_end  : int = 100,\n",
    "    sma_step : int = 20,\n",
    "    ema_start: int = 20,\n",
    "    ema_end  : int = 100,\n",
    "    ema_step : int = 20\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    --------\n",
    "    X: pd.DataFrame\n",
    "\n",
    "\n",
    "    Output\n",
    "    --------\n",
    "    X: pd.DataFrame\n",
    "    \"\"\"\n",
    "    close = data.Close\n",
    "\n",
    "    # SMA\n",
    "    data = addSMA(data=data, sma_start=sma_start, sma_end=sma_end, sma_step=sma_step)\n",
    "\n",
    "    # EMA\n",
    "    data = addEMA(data=data, ema_start=ema_start, ema_end=ema_end, ema_step=ema_step)\n",
    "\n",
    "    # RSI\n",
    "    data[\"RSI\"] = ta.momentum.RSIIndicator(data.Close).rsi()\n",
    "  \n",
    "    # MACD\n",
    "    data[\"MACD\"] = ta.trend.MACD(data.Close).macd()\n",
    "\n",
    "    # ATR\n",
    "    data[\"ATR\"] = ta.volatility.AverageTrueRange(data.High, data.Low, data.Close).average_true_range()\n",
    "\n",
    "    # BollingerBands\n",
    "    upper = ta.volatility.BollingerBands(data.Close).bollinger_hband()\n",
    "    lower = ta.volatility.BollingerBands(data.Close).bollinger_lband()\n",
    "\n",
    "    data[\"BB_upper\"] = (upper - close) / close\n",
    "    data[\"BB_lower\"] = (lower - close) / close\n",
    "    data[\"BB_width\"] = (upper - lower) / close\n",
    "\n",
    "    # Garman Klass Volatility\n",
    "    data[\"garman_klass_vol\"] = ((np.log(data.High)-np.log(data.Low))**2)/2-(2*np.log(2)-1)*((np.log(data.Close)-np.log(data.Open))**2)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data,\n",
    "               PCA_components = 8):\n",
    "  # Feature generation\n",
    "  data_features = feature_generation(data)\n",
    "\n",
    "  # Feature\n",
    "  remove_columns = [\"Open\",\n",
    "                    \"High\",\n",
    "                    \"Low\",\n",
    "                    \"Close\"]\n",
    "  features = data_features.drop(remove_columns, axis=1).dropna()\n",
    "\n",
    "  # normalize\n",
    "  scaler = StandardScaler()\n",
    "  features = pd.DataFrame(\n",
    "    scaler.fit_transform(features),\n",
    "    index=features.index,\n",
    "    columns=features.columns)\n",
    "\n",
    "  # PCA\n",
    "  pca = PCA(n_components=PCA_components)\n",
    "  features = pd.DataFrame(\n",
    "    pca.fit_transform(features),\n",
    "    index=features.index)\n",
    "  \n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM_input(data, time_steps=10):\n",
    "    num_samples = data.shape[0] - time_steps + 1\n",
    "    X = np.array([data[i:i+time_steps] for i in range(num_samples)])\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    lstm_stacks = 3\n",
    "\n",
    "    inputs = keras.Input((10, 8)) # Hard-coded timestep and number of features\n",
    "    outputs = None\n",
    "\n",
    "    for n in range(lstm_stacks):\n",
    "        if outputs is None:\n",
    "            outputs = keras.layers.LSTM(64, return_sequences=True)(inputs)\n",
    "            outputs = keras.layers.Dropout(0.05)(outputs)\n",
    "        else:\n",
    "            if n < lstm_stacks - 1:\n",
    "                outputs = keras.layers.LSTM(64, return_sequences=True)(outputs)\n",
    "                outputs = keras.layers.Dropout(0.05)(outputs)\n",
    "            else:\n",
    "                outputs = keras.layers.LSTM(64)(outputs)\n",
    "                outputs = keras.layers.Dropout(0.05)(outputs)\n",
    "    outputs = keras.layers.Dense(1)(outputs)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    loss = keras.losses.MeanSquaredError()\n",
    "    model.compile(optimizer=optimizer,loss=loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Trading Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coin:\n",
    "    def __init__(self, symbol, ohlcv):\n",
    "        self.symbol = symbol\n",
    "        self.ohlcv = ohlcv\n",
    "        self.logret = self.calculate_logret()\n",
    "        self.trading_history = []  # List to store trading history\n",
    "        self.volatility = self.calculate_volatility()\n",
    "        self.features = preprocess(\n",
    "            pd.concat([\n",
    "                self.ohlcv,\n",
    "                self.logret,\n",
    "                self.volatility],\n",
    "                axis=1))\n",
    "        self.y = self.logret.shift(-1)\n",
    "\n",
    "    def calculate_logret(self):\n",
    "        return pd.DataFrame(\n",
    "            np.log((self.ohlcv.Close / self.ohlcv.Close.shift(1)))).rename(columns={\"Close\": \"logret\"})\n",
    "\n",
    "    def calculate_volatility(self):\n",
    "        return pd.DataFrame(\n",
    "            self.logret.rolling(window=14).std()).rename(columns={\"logret\": \"vol\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Market:\n",
    "    def __init__(\n",
    "        self,\n",
    "        cash = 10000):\n",
    "        self.coins = {}  # Dictionary to store coins\n",
    "        self.init_cash = cash\n",
    "        self.cash = self.init_cash  # Initial cash balance\n",
    "        self.assets = {}  # Dictionary to store quantity of each asset\n",
    "        self.prices = pd.DataFrame()\n",
    "\n",
    "        self.margin_rate = 0.004\n",
    "\n",
    "\n",
    "    def add_coin(self, coin):\n",
    "        self.coins[coin.symbol] = coin\n",
    "        self.assets[coin.symbol] = 0  # Initialize asset quantity to 0\n",
    "\n",
    "        close = pd.DataFrame(coin.ohlcv.Close).rename(columns={\"Close\": coin.symbol})\n",
    "        self.prices = pd.concat([self.prices, close], axis=1)\n",
    "        \n",
    "        self.coins[coin.symbol].trading_history = []\n",
    "        self.coins[coin.symbol].position = \"Closed\"\n",
    "\n",
    "        self.coins[coin.symbol].entry_cost = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.cash = self.init_cash\n",
    "        for symbol in self.coins:\n",
    "            self.coins[symbol].trading_history = []\n",
    "            self.assets[symbol] = 0  # Initialize asset quantity to 0\n",
    "            self.coins[symbol].position = \"Closed\"\n",
    "            self.coins[symbol].entry_cost = 0\n",
    "\n",
    "    def trade(self, symbol, action, quantity, price, time):\n",
    "        if action == \"long\":\n",
    "            self.market_long(symbol, quantity, price, time)\n",
    "\n",
    "        if action == \"short\":\n",
    "            self.market_short(symbol, quantity, price, time)\n",
    "\n",
    "        elif action == \"close\":\n",
    "            if self.coins[symbol].position != \"Closed\":\n",
    "                if self.coins[symbol].position == \"Long\":\n",
    "                    self.market_long_close(symbol, quantity, price, time)\n",
    "                if self.coins[symbol].position == \"Short\":\n",
    "                    self.market_short_close(symbol, quantity, price, time)\n",
    "\n",
    "    def market_long(self, symbol, quantity, price, time):        \n",
    "        available_margin = self.cash\n",
    "        maintenance_margin = quantity * price * self.margin_rate\n",
    "        margin_balance = available_margin\n",
    "        margin_ratio = maintenance_margin / margin_balance\n",
    "\n",
    "        if margin_ratio < 1:\n",
    "            self.assets[symbol] += quantity\n",
    "            self.coins[symbol].trading_history.append(\n",
    "                {\n",
    "                    \"action\": \"long\",\n",
    "                    \"quantity\": quantity,\n",
    "                    \"price\": price,\n",
    "                    \"time\": time\n",
    "                })\n",
    "            self.coins[symbol].entry_cost = quantity * price\n",
    "            self.coins[symbol].position = \"Long\"\n",
    "\n",
    "    def market_long_close(self, symbol, quantity, price, time):\n",
    "        notional_value = quantity * price\n",
    "\n",
    "        self.cash += notional_value - self.coins[symbol].entry_cost\n",
    "\n",
    "        self.assets[symbol] -= quantity\n",
    "        self.coins[symbol].trading_history.append(\n",
    "            {\n",
    "                \"action\": \"close\",\n",
    "                \"quantity\": quantity,\n",
    "                \"price\": price,\n",
    "                \"time\": time\n",
    "            })\n",
    "        self.coins[symbol].entry_cost = 0\n",
    "        self.coins[symbol].position = \"Closed\"\n",
    "\n",
    "    def market_short(self, symbol, quantity, price, time):\n",
    "        self.assets[symbol] += quantity\n",
    "        self.coins[symbol].trading_history.append(\n",
    "            {\n",
    "                \"action\": \"short\",\n",
    "                \"quantity\": quantity,\n",
    "                \"price\": price,\n",
    "                \"time\": time\n",
    "            })\n",
    "        self.coins[symbol].entry_cost = quantity * price\n",
    "        self.coins[symbol].position = \"Short\"\n",
    "\n",
    "    def market_short_close(self, symbol, quantity, price, time):\n",
    "        notional_value = quantity * price\n",
    "\n",
    "        self.cash += notional_value - self.coins[symbol].entry_cost\n",
    "\n",
    "        self.assets[symbol] -= quantity\n",
    "        self.coins[symbol].trading_history.append(\n",
    "            {\n",
    "                \"action\": \"close\",\n",
    "                \"quantity\": quantity,\n",
    "                \"price\": price,\n",
    "                \"time\": time\n",
    "            })\n",
    "        self.coins[symbol].entry_cost = 0\n",
    "        self.coins[symbol].position = \"Closed\"\n",
    "\n",
    "    def get_margin_ratio(self, time):\n",
    "        maintenance_margin = 0\n",
    "        margin_balance = self.cash\n",
    "        for symbol in self.coins:\n",
    "            qty = self.assets[symbol]\n",
    "            price = self.prices.loc[time, symbol]\n",
    "            entry_cost = self.coins[symbol].entry_cost\n",
    "\n",
    "            notional_value = qty * price\n",
    "\n",
    "            maintenance_margin += notional_value * self.margin_rate\n",
    "            margin_balance += notional_value - entry_cost\n",
    "        \n",
    "        margin_ratio = maintenance_margin / margin_balance\n",
    "\n",
    "        return margin_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains all the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [\n",
    "    \"ADAUSDT\",\n",
    "    \"BNBUSDT\",\n",
    "    \"BTCUSDT\",\n",
    "    \"EOSUSDT\",\n",
    "    \"ETHUSDT\",\n",
    "    \"LTCUSDT\",\n",
    "    \"NEOUSDT\",\n",
    "    \"QTUMUSDT\",\n",
    "    \"XRPUSDT\"\n",
    "    ]\n",
    "\n",
    "interval = \"15m\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section outputs training and testing data for the use of the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the market for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_train = Market()\n",
    "for symbol in symbols:\n",
    "    data_train = pd.read_csv(f\"Binance Data/Training/{interval}/{symbol}.csv\", index_col=\"index\")\n",
    "    data_train = data_train.set_index(pd.DatetimeIndex(pd.to_datetime(data_train.index)))\n",
    "    coin = Coin(symbol, data_train)\n",
    "    market_train.add_coin(coin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_val = Market()\n",
    "for symbol in symbols:\n",
    "    data_val = pd.read_csv(f\"Binance Data/Validation/{interval}/{symbol}.csv\", index_col=\"index\")\n",
    "    data_val = data_val.set_index(pd.DatetimeIndex(pd.to_datetime(data_val.index)))\n",
    "    coin = Coin(symbol, data_val)\n",
    "    market_val.add_coin(coin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - loss: 1.7586e-04 - val_loss: 3.3378e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.9276e-05 - val_loss: 3.1998e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.5937e-05 - val_loss: 2.8807e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.4739e-05 - val_loss: 2.8978e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.4614e-05 - val_loss: 2.8272e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.2617e-05 - val_loss: 2.8644e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.2972e-05 - val_loss: 2.8120e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.7761e-05 - val_loss: 2.8628e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.2150e-05 - val_loss: 2.8050e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.4238e-05 - val_loss: 2.8054e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.2453e-05 - val_loss: 2.8910e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.0923e-05 - val_loss: 2.8825e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.2670e-05 - val_loss: 2.9202e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 5.0986e-05 - val_loss: 2.8329e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.0787e-05 - val_loss: 2.8475e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.1751e-05 - val_loss: 2.9494e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.2739e-05 - val_loss: 2.8978e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.1626e-05 - val_loss: 2.8159e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.3171e-05 - val_loss: 2.9552e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.0131e-05 - val_loss: 2.8540e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 4.9636e-05 - val_loss: 2.9975e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 5.1717e-05 - val_loss: 2.9346e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 5.0938e-05 - val_loss: 3.0889e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 4.8851e-05 - val_loss: 2.9651e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 4.9269e-05 - val_loss: 2.9538e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 4.8865e-05 - val_loss: 2.9322e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 5.0906e-05 - val_loss: 2.9663e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 4.9745e-05 - val_loss: 3.5366e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.7758e-05 - val_loss: 3.2553e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 4.8810e-05 - val_loss: 3.0068e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 4.8712e-05 - val_loss: 3.8131e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.7150e-05 - val_loss: 2.9305e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.7975e-05 - val_loss: 3.2392e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.8121e-05 - val_loss: 3.1323e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.7363e-05 - val_loss: 3.2407e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.8443e-05 - val_loss: 3.2432e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.8084e-05 - val_loss: 3.3527e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 4.7163e-05 - val_loss: 3.3267e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 4.6742e-05 - val_loss: 3.7536e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.8785e-05 - val_loss: 3.1666e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.6736e-05 - val_loss: 3.3065e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.6514e-05 - val_loss: 3.2267e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.6722e-05 - val_loss: 3.1563e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.4709e-05 - val_loss: 3.0783e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.4754e-05 - val_loss: 3.3061e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.3841e-05 - val_loss: 3.5435e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.6000e-05 - val_loss: 3.2940e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.5014e-05 - val_loss: 3.2432e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.4092e-05 - val_loss: 3.3035e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.4057e-05 - val_loss: 3.4422e-05\n",
      "Epoch 1/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 4.1682e-05 - val_loss: 1.7728e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 3.8162e-05 - val_loss: 1.7207e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 3.9653e-05 - val_loss: 1.7379e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 3.8364e-05 - val_loss: 2.1209e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 3.7583e-05 - val_loss: 1.8826e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.7502e-05 - val_loss: 1.9826e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 3.8410e-05 - val_loss: 1.8398e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 3.6897e-05 - val_loss: 2.0116e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 3.4743e-05 - val_loss: 1.9848e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.6941e-05 - val_loss: 2.2063e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.6224e-05 - val_loss: 2.0433e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.4132e-05 - val_loss: 1.8891e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.3755e-05 - val_loss: 2.3899e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.3686e-05 - val_loss: 2.6607e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.3748e-05 - val_loss: 2.4661e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.3737e-05 - val_loss: 2.3921e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.3565e-05 - val_loss: 2.3918e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.2720e-05 - val_loss: 2.3184e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.2748e-05 - val_loss: 2.3498e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.3643e-05 - val_loss: 2.4752e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.1562e-05 - val_loss: 2.3413e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.1953e-05 - val_loss: 2.4681e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.1586e-05 - val_loss: 2.4058e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.1650e-05 - val_loss: 2.1893e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 3.0696e-05 - val_loss: 2.3231e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.1100e-05 - val_loss: 2.6420e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 3.1012e-05 - val_loss: 2.5435e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 3.0065e-05 - val_loss: 2.5716e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 3.0866e-05 - val_loss: 2.4365e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.9769e-05 - val_loss: 2.5218e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 2.9715e-05 - val_loss: 2.5298e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.9934e-05 - val_loss: 2.4386e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 2.9719e-05 - val_loss: 2.1807e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.9200e-05 - val_loss: 2.6029e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 3.0083e-05 - val_loss: 2.3766e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.9479e-05 - val_loss: 2.4449e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.9329e-05 - val_loss: 2.9085e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.9060e-05 - val_loss: 2.5294e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.9171e-05 - val_loss: 2.5068e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.8946e-05 - val_loss: 2.4839e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.8042e-05 - val_loss: 2.4039e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.8173e-05 - val_loss: 2.6443e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.8017e-05 - val_loss: 2.4360e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.7847e-05 - val_loss: 2.4442e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.7530e-05 - val_loss: 2.4719e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.7841e-05 - val_loss: 2.5505e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.7883e-05 - val_loss: 2.5590e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.7594e-05 - val_loss: 2.4902e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.6477e-05 - val_loss: 2.6945e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 2.6981e-05 - val_loss: 2.4911e-05\n",
      "Epoch 1/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.9804e-05 - val_loss: 1.2262e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.8484e-05 - val_loss: 1.3002e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.9020e-05 - val_loss: 1.3015e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.7248e-05 - val_loss: 1.4210e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.7242e-05 - val_loss: 1.5577e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.7312e-05 - val_loss: 1.5481e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.8130e-05 - val_loss: 1.5204e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.7700e-05 - val_loss: 1.4975e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.6622e-05 - val_loss: 1.5033e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.6102e-05 - val_loss: 1.5288e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.7278e-05 - val_loss: 1.5903e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.6750e-05 - val_loss: 1.5243e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.6677e-05 - val_loss: 1.7092e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.5716e-05 - val_loss: 1.7142e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.5883e-05 - val_loss: 1.5059e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.5661e-05 - val_loss: 1.7636e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.5135e-05 - val_loss: 1.7805e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 1.5538e-05 - val_loss: 1.6265e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.5888e-05 - val_loss: 1.5690e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.5794e-05 - val_loss: 1.5303e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.5382e-05 - val_loss: 1.6988e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.5622e-05 - val_loss: 1.5912e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.5046e-05 - val_loss: 1.5751e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.5311e-05 - val_loss: 1.6220e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.5013e-05 - val_loss: 1.6418e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.4684e-05 - val_loss: 1.6118e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.5087e-05 - val_loss: 1.8020e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 1.4785e-05 - val_loss: 1.6633e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4904e-05 - val_loss: 1.9305e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4880e-05 - val_loss: 1.6872e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4645e-05 - val_loss: 1.6503e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4300e-05 - val_loss: 1.6890e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4515e-05 - val_loss: 1.8223e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4192e-05 - val_loss: 1.7257e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4695e-05 - val_loss: 1.7126e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4666e-05 - val_loss: 1.6866e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4243e-05 - val_loss: 1.6907e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4043e-05 - val_loss: 1.7979e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.3837e-05 - val_loss: 1.7101e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.3884e-05 - val_loss: 1.9665e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4269e-05 - val_loss: 1.9251e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4287e-05 - val_loss: 1.8974e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.3729e-05 - val_loss: 1.7346e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4365e-05 - val_loss: 1.8473e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.3840e-05 - val_loss: 2.0168e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.3782e-05 - val_loss: 1.8497e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.4023e-05 - val_loss: 1.7755e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.3642e-05 - val_loss: 1.8069e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.3759e-05 - val_loss: 1.8516e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 1.3748e-05 - val_loss: 1.7657e-05\n",
      "Epoch 1/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 4.9593e-05 - val_loss: 2.7433e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 4.5027e-05 - val_loss: 2.7909e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 4.2499e-05 - val_loss: 2.8313e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 4.2953e-05 - val_loss: 2.7791e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 4.5289e-05 - val_loss: 2.7747e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 4.3689e-05 - val_loss: 2.9515e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 4.2288e-05 - val_loss: 2.8802e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 4.1692e-05 - val_loss: 2.8797e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 4.1419e-05 - val_loss: 2.9817e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 4.0811e-05 - val_loss: 3.0275e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.9198e-05 - val_loss: 3.1811e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.8329e-05 - val_loss: 2.9794e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.8253e-05 - val_loss: 2.9895e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.8118e-05 - val_loss: 2.9976e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.8952e-05 - val_loss: 2.9671e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.7343e-05 - val_loss: 3.0698e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.8767e-05 - val_loss: 3.0938e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.7107e-05 - val_loss: 3.1201e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.7099e-05 - val_loss: 3.0744e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.8293e-05 - val_loss: 3.1688e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.6230e-05 - val_loss: 3.0798e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.6219e-05 - val_loss: 3.3836e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.8022e-05 - val_loss: 3.0777e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.5520e-05 - val_loss: 3.3477e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.4749e-05 - val_loss: 3.3679e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.5217e-05 - val_loss: 3.2014e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.7884e-05 - val_loss: 3.2017e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.4125e-05 - val_loss: 3.2828e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.3911e-05 - val_loss: 3.4269e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.5546e-05 - val_loss: 3.3385e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - loss: 3.4241e-05 - val_loss: 3.3946e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.4268e-05 - val_loss: 3.4759e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.3840e-05 - val_loss: 3.3856e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.3634e-05 - val_loss: 3.5770e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.4652e-05 - val_loss: 3.6764e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.4008e-05 - val_loss: 3.3283e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.3331e-05 - val_loss: 3.7178e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.3168e-05 - val_loss: 3.3700e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.1500e-05 - val_loss: 3.7088e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.5020e-05 - val_loss: 3.3454e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.2833e-05 - val_loss: 3.3488e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.2603e-05 - val_loss: 3.3733e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.2009e-05 - val_loss: 3.3553e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.2171e-05 - val_loss: 3.3617e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.3511e-05 - val_loss: 3.2948e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.2703e-05 - val_loss: 3.3775e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.1082e-05 - val_loss: 3.4961e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.1505e-05 - val_loss: 3.3900e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.1772e-05 - val_loss: 3.3693e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.1596e-05 - val_loss: 3.4035e-05\n",
      "Epoch 1/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.3641e-05 - val_loss: 2.2854e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.0367e-05 - val_loss: 2.2208e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.8953e-05 - val_loss: 2.3712e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.8420e-05 - val_loss: 2.5463e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.6834e-05 - val_loss: 2.4207e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.7555e-05 - val_loss: 2.5222e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.6753e-05 - val_loss: 2.4785e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.7134e-05 - val_loss: 2.4913e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.6544e-05 - val_loss: 2.4008e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.6205e-05 - val_loss: 2.4575e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.5595e-05 - val_loss: 2.4259e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.5490e-05 - val_loss: 2.4683e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.4883e-05 - val_loss: 2.4178e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.5226e-05 - val_loss: 2.8380e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.4646e-05 - val_loss: 2.5915e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.5111e-05 - val_loss: 2.5861e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.4486e-05 - val_loss: 2.6038e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.3931e-05 - val_loss: 2.5466e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.4215e-05 - val_loss: 2.6277e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.3919e-05 - val_loss: 2.9502e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.3784e-05 - val_loss: 2.6464e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.3767e-05 - val_loss: 2.6091e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.3461e-05 - val_loss: 2.4345e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.3288e-05 - val_loss: 2.6550e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.3702e-05 - val_loss: 2.6383e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.3369e-05 - val_loss: 2.7783e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.3731e-05 - val_loss: 2.7626e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.3634e-05 - val_loss: 2.7489e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2768e-05 - val_loss: 2.7856e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2746e-05 - val_loss: 2.8853e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2644e-05 - val_loss: 2.7671e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2345e-05 - val_loss: 2.6452e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2491e-05 - val_loss: 2.6425e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2354e-05 - val_loss: 2.7908e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2033e-05 - val_loss: 2.6434e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2507e-05 - val_loss: 2.8099e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2290e-05 - val_loss: 2.7700e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 2.2398e-05 - val_loss: 2.8105e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2459e-05 - val_loss: 2.6729e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2896e-05 - val_loss: 2.7595e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.1788e-05 - val_loss: 2.7983e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.1949e-05 - val_loss: 2.8509e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.1614e-05 - val_loss: 2.9055e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.1571e-05 - val_loss: 2.7955e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2012e-05 - val_loss: 2.8716e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.1053e-05 - val_loss: 2.7133e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.1529e-05 - val_loss: 2.6944e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.1575e-05 - val_loss: 2.7054e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.1151e-05 - val_loss: 2.7887e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.1688e-05 - val_loss: 2.8042e-05\n",
      "Epoch 1/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.4774e-05 - val_loss: 2.5997e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.1954e-05 - val_loss: 2.9174e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.1003e-05 - val_loss: 2.8294e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.9686e-05 - val_loss: 3.0729e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.8917e-05 - val_loss: 2.8515e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.9102e-05 - val_loss: 3.2500e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 3.9228e-05 - val_loss: 2.9282e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6827e-05 - val_loss: 3.3023e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6806e-05 - val_loss: 3.0171e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4059e-05 - val_loss: 3.1560e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.5723e-05 - val_loss: 3.1054e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4486e-05 - val_loss: 3.0940e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.5410e-05 - val_loss: 3.0806e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.3197e-05 - val_loss: 3.3045e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4705e-05 - val_loss: 3.1577e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4039e-05 - val_loss: 3.2255e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4452e-05 - val_loss: 3.2722e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.3332e-05 - val_loss: 3.1468e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - loss: 3.4941e-05 - val_loss: 3.2734e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.2981e-05 - val_loss: 3.3288e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 3.3758e-05 - val_loss: 3.5495e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.3369e-05 - val_loss: 3.4098e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.5603e-05 - val_loss: 3.2915e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4640e-05 - val_loss: 3.4057e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.2484e-05 - val_loss: 3.4318e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.8455e-05 - val_loss: 3.3354e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.2803e-05 - val_loss: 3.3943e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.3697e-05 - val_loss: 3.1693e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.1818e-05 - val_loss: 3.4956e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.9196e-05 - val_loss: 3.3352e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.1549e-05 - val_loss: 3.3116e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.0590e-05 - val_loss: 3.4562e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.1281e-05 - val_loss: 3.4322e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.1365e-05 - val_loss: 3.3381e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.0663e-05 - val_loss: 3.4587e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.2201e-05 - val_loss: 3.6564e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.1268e-05 - val_loss: 3.5164e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.0455e-05 - val_loss: 3.6653e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.4042e-05 - val_loss: 3.3666e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.1034e-05 - val_loss: 3.6322e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.2222e-05 - val_loss: 3.3716e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.9857e-05 - val_loss: 3.2358e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.9361e-05 - val_loss: 3.6370e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.2066e-05 - val_loss: 3.5654e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.0573e-05 - val_loss: 3.4682e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.1707e-05 - val_loss: 3.5796e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.2089e-05 - val_loss: 3.5110e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.1289e-05 - val_loss: 3.4992e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.1633e-05 - val_loss: 3.4377e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.0039e-05 - val_loss: 3.6108e-05\n",
      "Epoch 1/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.2362e-05 - val_loss: 2.8692e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.9255e-05 - val_loss: 3.3042e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.7086e-05 - val_loss: 3.3330e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.5550e-05 - val_loss: 3.0960e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.5384e-05 - val_loss: 3.4874e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.3462e-05 - val_loss: 3.6875e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.2747e-05 - val_loss: 3.3586e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.2464e-05 - val_loss: 3.3293e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.2884e-05 - val_loss: 3.5325e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.0825e-05 - val_loss: 3.5729e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.1477e-05 - val_loss: 3.6433e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.1129e-05 - val_loss: 3.4871e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.9670e-05 - val_loss: 3.8985e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.9728e-05 - val_loss: 4.0593e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.0270e-05 - val_loss: 4.1786e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.9271e-05 - val_loss: 3.7914e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.0028e-05 - val_loss: 4.0582e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.8664e-05 - val_loss: 4.0053e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.9287e-05 - val_loss: 4.2766e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.9216e-05 - val_loss: 3.8144e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.8340e-05 - val_loss: 4.2609e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.8256e-05 - val_loss: 4.2732e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 3.7709e-05 - val_loss: 3.7369e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.8256e-05 - val_loss: 4.0521e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.7118e-05 - val_loss: 4.1847e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.7884e-05 - val_loss: 4.4415e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6953e-05 - val_loss: 4.8901e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.7202e-05 - val_loss: 4.4900e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.7730e-05 - val_loss: 4.6873e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6476e-05 - val_loss: 4.2749e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6581e-05 - val_loss: 4.5397e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.6727e-05 - val_loss: 4.1323e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.6742e-05 - val_loss: 4.4528e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6409e-05 - val_loss: 4.1236e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.5733e-05 - val_loss: 4.3137e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6389e-05 - val_loss: 4.5374e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.5058e-05 - val_loss: 4.1165e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.5826e-05 - val_loss: 5.2185e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6187e-05 - val_loss: 3.9742e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6271e-05 - val_loss: 4.2430e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4303e-05 - val_loss: 4.5476e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6327e-05 - val_loss: 4.2801e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 3.5331e-05 - val_loss: 4.1105e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.5178e-05 - val_loss: 4.3979e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4167e-05 - val_loss: 4.3844e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.5422e-05 - val_loss: 4.3630e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4073e-05 - val_loss: 4.1701e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.5669e-05 - val_loss: 4.3158e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4175e-05 - val_loss: 4.7855e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.3545e-05 - val_loss: 4.2983e-05\n",
      "Epoch 1/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 6.5833e-05 - val_loss: 3.7027e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 6.3499e-05 - val_loss: 3.8638e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 6.2830e-05 - val_loss: 4.0062e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.9656e-05 - val_loss: 4.3393e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.7649e-05 - val_loss: 4.5341e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.7496e-05 - val_loss: 4.5748e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.5754e-05 - val_loss: 4.7175e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.5929e-05 - val_loss: 4.6863e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.3081e-05 - val_loss: 4.4398e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.2803e-05 - val_loss: 4.8887e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.2701e-05 - val_loss: 4.7418e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.3115e-05 - val_loss: 4.8578e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.0791e-05 - val_loss: 5.1828e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 5.0336e-05 - val_loss: 5.3754e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.0090e-05 - val_loss: 4.9311e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.8883e-05 - val_loss: 5.7652e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.0126e-05 - val_loss: 5.4692e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.8961e-05 - val_loss: 5.5311e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 4.8399e-05 - val_loss: 5.5780e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.8392e-05 - val_loss: 4.8950e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.8878e-05 - val_loss: 5.1828e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.8414e-05 - val_loss: 5.4434e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.7325e-05 - val_loss: 5.5469e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.7886e-05 - val_loss: 6.2304e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 4.7718e-05 - val_loss: 5.5841e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.6390e-05 - val_loss: 5.6634e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.7158e-05 - val_loss: 5.3292e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.7003e-05 - val_loss: 5.5351e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 4.5734e-05 - val_loss: 6.2142e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.7136e-05 - val_loss: 5.2371e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.5431e-05 - val_loss: 5.4792e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.5745e-05 - val_loss: 5.4306e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.4547e-05 - val_loss: 5.0652e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 4.5099e-05 - val_loss: 6.1880e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.5409e-05 - val_loss: 6.4829e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.4467e-05 - val_loss: 6.2833e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.4627e-05 - val_loss: 5.6447e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.3910e-05 - val_loss: 6.0838e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.4456e-05 - val_loss: 5.5837e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.4947e-05 - val_loss: 5.7736e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.4818e-05 - val_loss: 5.9282e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.3302e-05 - val_loss: 5.8664e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.4172e-05 - val_loss: 5.3386e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 4.3785e-05 - val_loss: 5.3479e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.2028e-05 - val_loss: 5.7495e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.2469e-05 - val_loss: 5.8353e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.2513e-05 - val_loss: 6.1139e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.1968e-05 - val_loss: 6.2764e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.3122e-05 - val_loss: 5.6752e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.2046e-05 - val_loss: 5.8823e-05\n",
      "Epoch 1/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 6.1943e-05 - val_loss: 2.4156e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 6.3356e-05 - val_loss: 2.5497e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 6.4717e-05 - val_loss: 2.3402e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.7524e-05 - val_loss: 2.4617e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 6.0044e-05 - val_loss: 2.4026e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.6267e-05 - val_loss: 2.4865e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.5005e-05 - val_loss: 2.4951e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.6384e-05 - val_loss: 2.4633e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.1762e-05 - val_loss: 2.4769e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.1586e-05 - val_loss: 2.4907e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.7455e-05 - val_loss: 2.5763e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.0732e-05 - val_loss: 2.5619e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.8086e-05 - val_loss: 2.5995e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.7185e-05 - val_loss: 2.5810e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 5.2613e-05 - val_loss: 2.9162e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.5166e-05 - val_loss: 2.9813e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.5055e-05 - val_loss: 2.8614e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.5531e-05 - val_loss: 2.8436e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.3863e-05 - val_loss: 3.0432e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.4061e-05 - val_loss: 2.9895e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.1721e-05 - val_loss: 2.9900e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.3835e-05 - val_loss: 2.9918e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.1907e-05 - val_loss: 3.1257e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 4.1224e-05 - val_loss: 3.2633e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.0885e-05 - val_loss: 3.2028e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.0676e-05 - val_loss: 3.1407e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.1845e-05 - val_loss: 3.1902e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.9742e-05 - val_loss: 3.1528e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.0658e-05 - val_loss: 3.2293e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.9445e-05 - val_loss: 3.1499e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.0603e-05 - val_loss: 3.2481e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.0060e-05 - val_loss: 3.2322e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.1270e-05 - val_loss: 3.1543e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.0220e-05 - val_loss: 3.2125e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.8131e-05 - val_loss: 3.1593e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.9141e-05 - val_loss: 3.2510e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6274e-05 - val_loss: 3.3085e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.7209e-05 - val_loss: 3.5200e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.9624e-05 - val_loss: 3.1581e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6922e-05 - val_loss: 3.4343e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6388e-05 - val_loss: 3.2737e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6889e-05 - val_loss: 3.4332e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.6359e-05 - val_loss: 3.3660e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.8473e-05 - val_loss: 3.3050e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.5461e-05 - val_loss: 3.2657e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.8307e-05 - val_loss: 3.3875e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.7292e-05 - val_loss: 3.5495e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.5849e-05 - val_loss: 3.2774e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4512e-05 - val_loss: 3.3644e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.3989e-05 - val_loss: 3.4006e-05\n"
     ]
    }
   ],
   "source": [
    "for symbol in symbols:\n",
    "    X_train = create_LSTM_input(market_train.coins[symbol].features)[:-1]\n",
    "    y_train = market_train.coins[symbol].logret[-X_train.shape[0]:]\n",
    "\n",
    "    X_val = create_LSTM_input(market_val.coins[symbol].features)[:-1]\n",
    "    y_val = market_val.coins[symbol].logret[-X_val.shape[0]:]\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs = 50,\n",
    "        validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM_full.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
