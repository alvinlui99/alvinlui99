{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35cdfdf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-06T16:40:58.035566Z",
     "iopub.status.busy": "2024-09-06T16:40:58.034433Z",
     "iopub.status.idle": "2024-09-06T16:40:58.931234Z",
     "shell.execute_reply": "2024-09-06T16:40:58.930072Z"
    },
    "papermill": {
     "duration": 0.905003,
     "end_time": "2024-09-06T16:40:58.934130",
     "exception": false,
     "start_time": "2024-09-06T16:40:58.029127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import kaggle_evaluation.mcts_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c84819e",
   "metadata": {
    "papermill": {
     "duration": 0.002596,
     "end_time": "2024-09-06T16:40:58.939894",
     "exception": false,
     "start_time": "2024-09-06T16:40:58.937298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The evaluation API requires that you set up a server which will respond to inference requests. We have already defined the server; you just need write the `predict` function. When we evaluate your submission on the hidden test set the client defined in `mcts_gateway` will run in a different container with direct access to the hidden test set and hand off the data in batches of 100. \n",
    "\n",
    "Your code will always have access to the published copies of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7a7dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T16:40:58.947242Z",
     "iopub.status.busy": "2024-09-06T16:40:58.946711Z",
     "iopub.status.idle": "2024-09-06T16:40:58.953264Z",
     "shell.execute_reply": "2024-09-06T16:40:58.952297Z"
    },
    "papermill": {
     "duration": 0.012964,
     "end_time": "2024-09-06T16:40:58.955586",
     "exception": false,
     "start_time": "2024-09-06T16:40:58.942622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame,\n",
    "            sample_sub: pl.DataFrame):\n",
    "    # Replace this function with your inference code.\n",
    "    # You can return either a Pandas or Polars dataframe, though Polars is recommended.\n",
    "    # Each batch of predictions (except the very first) must be returned within 10 minutes of the batch features being provided.\n",
    "    return sample_sub.with_columns(pl.col('utility_agent1') + 0.123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e7555",
   "metadata": {
    "papermill": {
     "duration": 0.002593,
     "end_time": "2024-09-06T16:40:58.961074",
     "exception": false,
     "start_time": "2024-09-06T16:40:58.958481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When your notebook is run on the hidden test set, `inference_server.serve` must be called within 15 minutes of the notebook starting or the gateway will throw an error. If you need more than 15 minutes to load your model you can do so during the very first `predict` call, which does not have the usual 10 minute response deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06774e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T16:40:58.968587Z",
     "iopub.status.busy": "2024-09-06T16:40:58.967631Z",
     "iopub.status.idle": "2024-09-06T16:40:59.431909Z",
     "shell.execute_reply": "2024-09-06T16:40:59.430396Z"
    },
    "papermill": {
     "duration": 0.470991,
     "end_time": "2024-09-06T16:40:59.434741",
     "exception": false,
     "start_time": "2024-09-06T16:40:58.963750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab662a1",
   "metadata": {
    "papermill": {
     "duration": 0.002567,
     "end_time": "2024-09-06T16:40:59.440354",
     "exception": false,
     "start_time": "2024-09-06T16:40:59.437787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that nothing past `inference_server.serve()` will be run when your submission is evaluated on the hidden test set."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9506970,
     "sourceId": 70089,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.893368,
   "end_time": "2024-09-06T16:40:59.964716",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-06T16:40:55.071348",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
